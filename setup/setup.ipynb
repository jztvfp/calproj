{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup\n",
    "\n",
    "Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a75790e8-87a4-49cc-b8ef-96ce0b935dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"project\"\n",
    "br_schema = dbName = db = \"bronze\"\n",
    "sl_schema =  \"silver\"\n",
    "gd_schema =  \"gold\"\n",
    "\n",
    "data_volume_name = \"source_data\"\n",
    "test_volume_name = \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create UC objects"
    }
   },
   "outputs": [],
   "source": [
    "## Set up Catalog, schemas and volumes\n",
    "spark.sql(f'CREATE CATALOG IF NOT EXISTS `{catalog}`')\n",
    "spark.sql(f'USE CATALOG `{catalog}`')\n",
    "spark.sql(f'CREATE SCHEMA IF NOT EXISTS `{catalog}`.`{gd_schema}`')\n",
    "spark.sql(f'CREATE SCHEMA IF NOT EXISTS `{catalog}`.`{sl_schema}`')\n",
    "spark.sql(f'CREATE SCHEMA IF NOT EXISTS `{catalog}`.`{br_schema}`')\n",
    "spark.sql(f'USE SCHEMA `{br_schema}`')\n",
    "spark.sql(f'CREATE VOLUME IF NOT EXISTS `{catalog}`.`{br_schema}`.`{data_volume_name}`')\n",
    "data_volume_folder =  f\"/Volumes/{catalog}/{db}/{data_volume_name}\"\n",
    "spark.sql(f'CREATE VOLUME IF NOT EXISTS `{catalog}`.`{br_schema}`.`{test_volume_name}`')\n",
    "test_volume_folder =  f\"/Volumes/{catalog}/{db}/{test_volume_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5afa2768-a40e-4fc1-9f68-396f5d24578f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Copy Data to the Volumes"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Copy the test_data.csv file\n",
    "for file in glob.glob(\"../fixtures/test*.csv\"):\n",
    "    shutil.copy(file, test_volume_folder + \"/\")\n",
    "\n",
    "# Copy the data_group*.csv files\n",
    "for file in glob.glob(\"../fixtures/data_group*.csv\"):\n",
    "    shutil.copy(file, data_volume_folder + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0248dc-c0f3-49ac-a4a1-87998cf5b647",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Expectations table"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    " # tablename         quality            name              constraint\n",
    " (\"turbine_data\",   \"bronze\",   \"correct_schema\", \"_rescued_data IS NULL\"),\n",
    " (\"turbine_data\",   \"bronze\",   \"valid_id\", \"turbine_id IS NOT NULL AND turbine_id > 0\"),\n",
    " (\"turbine_data\",   \"bronze\",   \"timestamp\",    \"timestamp IS NOT NULL AND timestamp < current_timestamp()\"),\n",
    " (\"turbine_data\",   \"silver\",    \"wind_speed\",  \"windspeed IS NOT NULL AND windspeed > 0\"),\n",
    " (\"turbine_data\",   \"silver\",    \"wind_direction\",  \"winddirection IS NOT NULL AND winddirection < 360\")\n",
    "]\n",
    "\n",
    "spark.createDataFrame(data=data, schema=[\"tablename\", \"quality\",\"name\", \"constraint\"]).write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{br_schema}.expectations\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "setup",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
