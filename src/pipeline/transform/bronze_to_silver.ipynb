{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a626959-61c8-4bba-84d2-2a4ecab1f7ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "# Transform Pipeline\n",
    "\n",
    "Transform the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9198e987-5606-403d-9f6d-8f14e6a4017f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "source_table = spark.conf.get(\"source_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf66f040-7fbe-4d27-aa11-2b54869e30b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"project\"\n",
    "br_schema = \"bronze\"\n",
    "\n",
    "#Return the rules matching the tag as a format ready for DLT annotation.\n",
    "\n",
    "def get_rules(tablename, quality):\n",
    "  \"\"\"\n",
    "    loads data quality rules from csv file\n",
    "    :param tablename: tablename to match\n",
    "    :param quality: logical quality level\n",
    "    :return: dictionary of rules that matched the tag\n",
    "  \"\"\"\n",
    "  rules = {}\n",
    "  df = spark.table(f\"{catalog}.{br_schema}.expectations\").where(f\"tablename = '{tablename}' and quality ='{quality}'\")\n",
    "  for row in df.collect():\n",
    "    rules[row['name']] = row['constraint']\n",
    "  return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fc19dba-61fd-4a89-8f8c-24fee63bfb14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(\n",
    "  name = \"bronze_data_view\",\n",
    "  comment=\"Raw data from the turbines\"\n",
    ")\n",
    "@dlt.expect_all_or_drop(get_rules('turbine_data','silver'))\n",
    "def bronze_data_view():\n",
    "  df = (\n",
    "    spark.readStream.table(source_table).select(\n",
    "      F.sha1(F.concat(F.col(\"timestamp\").cast(\"string\"), F.col(\"turbine_id\").cast(\"string\"))).alias(\"ReadingKey\"),\n",
    "      F.col(\"timestamp\").alias(\"ReadingDate\"),\n",
    "      F.col(\"turbine_id\").alias(\"TurbineNumber\"),\n",
    "      ## Smooth next three fields based on last successful reading\n",
    "      F.col(\"wind_speed\").alias(\"WindSpeed\"),\n",
    "      F.col(\"wind_direction\").alias(\"WindDirection\"),\n",
    "      F.col(\"power_output\").alias(\"PowerOutput\"),\n",
    "      F.col(\"filename\"),\n",
    "      F.col(\"processedtime\").alias(\"loadeddatetime\")\n",
    "      )\n",
    "  )\n",
    "  return df\n",
    "\n",
    "##TODO\n",
    "## handle missing wind speed, wind direction and power output\n",
    "\n",
    "dlt.create_streaming_table(\n",
    "  name = \"turbine_data\",\n",
    "  table_properties = {\"quality\": \"silver\"},\n",
    "  comment=\"Cleaned and deduplicated turbine data\"\n",
    "  )\n",
    "\n",
    "dlt.apply_changes(\n",
    "    target = \"turbine_data\",\n",
    "    source = \"bronze_data_view\",\n",
    "    keys = [\"ReadingKey\"],\n",
    "    sequence_by = F.col(\"ReadingDate\"),\n",
    "    except_column_list = [\"loadeddatetime\", \"filename\"],\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_to_silver",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
